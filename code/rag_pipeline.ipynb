{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T10:01:20.657444Z",
     "start_time": "2024-03-22T10:00:36.005174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installs\n",
    "%pip install -q langchain langchain-community langchain-openai fastembed qdrant-client oxrdflib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from operator import itemgetter\n",
    "import os\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import format_document\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from rdflib import Graph\n",
    "from typing import Any, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OpenAI key\n",
    "f = open(\"../data/openai-key.txt\", \"r\")\n",
    "lst = f.readlines()\n",
    "f.close() \n",
    "\n",
    "openai_api_key = lst[-1]\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_class_query() -> str:\n",
    "    \"\"\"\n",
    "    Query to extract class labels\n",
    "    \"\"\"\n",
    "    \n",
    "    return \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        PREFIX rdfs:  <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX owl:  <http://www.w3.org/2002/07/owl#>\n",
    "        PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "        PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "        SELECT ?uri ?pred ?label ?type\n",
    "        WHERE {\n",
    "            ?uri a ?type ;\n",
    "                ?pred ?label .\n",
    "            FILTER (\n",
    "                ?type = owl:Class\n",
    "            )\n",
    "            FILTER (\n",
    "                ?pred = rdfs:label ||\n",
    "                ?pred = skos:prefLabel ||\n",
    "                ?pred = skos:altLabel ||\n",
    "                ?pred = skos:definition ||\n",
    "                ?pred = rdfs:comment ||\n",
    "                ?pred = dcterms:description ||\n",
    "                ?pred = dc:title\n",
    "            )\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def _get_property_query() -> str:\n",
    "    \"\"\"\n",
    "    Query to extract property labels\n",
    "    \"\"\"\n",
    "    \n",
    "    return \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        PREFIX rdfs:  <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX owl:  <http://www.w3.org/2002/07/owl#>\n",
    "        PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "        PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "        SELECT ?uri ?pred ?label ?type\n",
    "        WHERE {\n",
    "            ?uri a ?type ;\n",
    "                ?pred ?label .\n",
    "            FILTER (\n",
    "                ?type = owl:DatatypeProperty ||\n",
    "                ?type = owl:ObjectProperty\n",
    "            )\n",
    "            FILTER (\n",
    "                ?pred = rdfs:label ||\n",
    "                ?pred = skos:prefLabel ||\n",
    "                ?pred = skos:altLabel ||\n",
    "                ?pred = skos:definition ||\n",
    "                ?pred = rdfs:comment ||\n",
    "                ?pred = dcterms:description ||\n",
    "                ?pred = dc:title\n",
    "            )\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class OntologyLoader(BaseLoader):\n",
    "    \"\"\"\n",
    "    Load an OWL ontology and extract classes and properties as documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ontology_url: str, format: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the OntologyLoader.\n",
    "\n",
    "        Args:\n",
    "            ontology_url (str): URL of the OWL ontology to be loaded.\n",
    "            format (str): Format of the OWL ontology to be loaded.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ontology_url = ontology_url\n",
    "        self.format = format\n",
    "        self.graph = Graph(store=\"Oxigraph\")\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Load and return documents (classes and properties) from the OWL ontology.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.format:\n",
    "            self.graph.parse(self.ontology_url, format=self.format)\n",
    "        else:\n",
    "            self.graph.parse(self.ontology_url)\n",
    "\n",
    "        # Extract classes and properties as documents\n",
    "        docs: List[Document] = []\n",
    "        for cls in self.graph.query(_get_class_query()):\n",
    "            docs.append(self._create_document(cls))\n",
    "        for prop in self.graph.query(_get_property_query()):\n",
    "            docs.append(self._create_document(prop))\n",
    "        return docs\n",
    "\n",
    "    def _create_document(self, result_row: Any) -> Document:\n",
    "        \"\"\"\n",
    "        Create a Document object from a query result row.\n",
    "        \"\"\"\n",
    "        \n",
    "        label = str(result_row.label)\n",
    "        return Document(\n",
    "            page_content=label,\n",
    "            metadata={\n",
    "                \"label\": label,\n",
    "                \"uri\": str(result_row.uri),\n",
    "                \"type\": str(result_row.type),\n",
    "                \"predicate\": str(result_row.pred),\n",
    "                \"ontology\": self.ontology_url,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_retreiver(embed_name=\"BAAI/bge-small-en-v1.5\",\n",
    "                    embed_max_length=512,\n",
    "                    ontology_url=\"../data/health.ttl\",\n",
    "                    ontology_format=\"ttl\",\n",
    "                    split_size=1000,\n",
    "                    split_overlap=200,\n",
    "                    k = 45):\n",
    "\n",
    "    flag_embeddings = FastEmbedEmbeddings(model_name=embed_name, max_length=embed_max_length)\n",
    "    loader = OntologyLoader(ontology_url=ontology_url, format=ontology_format)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Split the documents into chunks if necessary\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=split_size, chunk_overlap=split_overlap)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    vectorstore = Qdrant.from_documents(\n",
    "        splits,\n",
    "        flag_embeddings,\n",
    "        collection_name=\"ontologies\",\n",
    "        location=\":memory:\",\n",
    "    )\n",
    "\n",
    "    # K is the number of source documents retrieved\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    return retriever\n",
    "\n",
    "def prep_llm(temp=0):\n",
    "    llm = OpenAI(temperature=temp)\n",
    "    return llm\n",
    "\n",
    "def prep_memory():\n",
    "    # Create the memory object that is used to add messages\n",
    "    memory = ConversationBufferMemory(return_messages=True, output_key=\"answer\", input_key=\"question\")\n",
    "\n",
    "    # Add a \"memory\" key to the input object\n",
    "    loaded_memory = RunnablePassthrough.assign(chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),)\n",
    "\n",
    "    return memory, loaded_memory\n",
    "\n",
    "def prep_prompts(reform_template, answer_template):\n",
    "    REFORM_QUESTION_PROMPT = PromptTemplate.from_template(reform_template)\n",
    "    ANSWER_PROMPT = ChatPromptTemplate.from_template(answer_template)\n",
    "    DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"Concept label: {page_content} | URI: {uri} | Type: {type} | Predicate: {predicate} | Ontology: {ontology}\")\n",
    "\n",
    "    return REFORM_QUESTION_PROMPT, ANSWER_PROMPT, DEFAULT_DOCUMENT_PROMPT\n",
    "\n",
    "def _combine_documents(docs, document_prompt, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "def prep_chain(REFORM_QUESTION_PROMPT, llm, retriever, DEFAULT_DOCUMENT_PROMPT, ANSWER_PROMPT, loaded_memory):\n",
    "\n",
    "    # Reformulate the question using chat history\n",
    "    reformulated_question = {\n",
    "        \"reformulated_question\": {\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "        }\n",
    "        | REFORM_QUESTION_PROMPT\n",
    "        | llm\n",
    "        | StrOutputParser(),\n",
    "    }\n",
    "\n",
    "    # Retrieve the documents using the reformulated question\n",
    "    retrieved_documents = {\n",
    "        \"docs\": itemgetter(\"reformulated_question\") | retriever,\n",
    "        \"question\": lambda x: x[\"reformulated_question\"] #or print(\"ðŸ’­ Reformulated question:\", x[\"reformulated_question\"]),\n",
    "    }\n",
    "\n",
    "    # Construct the inputs for the final prompt using retrieved documents\n",
    "    final_inputs = {\n",
    "        \"context\": lambda x: _combine_documents(x[\"docs\"], DEFAULT_DOCUMENT_PROMPT),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "\n",
    "    # Generate the answer using the retrieved documents and answer prompt\n",
    "    answer = {\n",
    "        \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "        \"docs\": itemgetter(\"docs\"),\n",
    "    }\n",
    "\n",
    "    # Put the chain together\n",
    "    final_chain = loaded_memory | reformulated_question | retrieved_documents | answer\n",
    "\n",
    "    return final_chain\n",
    "\n",
    "def stream_chain(final_chain, memory: ConversationBufferMemory, memoryless, inputs: dict[str, str]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ask question, stream the answer output, and return the answer with source documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    output = {\"answer\": \"\"}\n",
    "    \n",
    "    for chunk in final_chain.stream(inputs):\n",
    "                \n",
    "        if \"docs\" in chunk:\n",
    "            output[\"docs\"] = [doc.dict() for doc in chunk[\"docs\"]]\n",
    "            #print(\"ðŸ“š Documents retrieved:\")\n",
    "            \n",
    "            for doc in output[\"docs\"]:\n",
    "                #print(f\"Â· {doc['page_content']} ({doc['metadata']['uri']})\")\n",
    "                continue\n",
    "\n",
    "        if \"answer\" in chunk:\n",
    "            output[\"answer\"] += chunk[\"answer\"]\n",
    "            #print(chunk[\"answer\"], end=\"\", flush=True)\n",
    "\n",
    "    if memoryless == 0:\n",
    "        memory.save_context(inputs, {\"answer\": output[\"answer\"]})\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hop(subject, q_lst, retriever, llm, reform_template, answer_template, memoryless=0):\n",
    "    \"\"\"\n",
    "    According to a given subject and a question list, performs multi-hop reasoning by asking questions in order.\n",
    "\n",
    "    Returns: Two-column array of questions and their answers.\n",
    "    \"\"\"\n",
    "    q_lst[0] = q_lst[0].format(concept = subject) # Inject the subject into questions\n",
    "\n",
    "    if memoryless not in [0, 1]: # Check if memorylessness is inputted correctly\n",
    "        print(\"Input memoryless parameter as binary.\")\n",
    "        return\n",
    "    \n",
    "    memory, loaded_memory = prep_memory() # Create empty memory\n",
    "    REFORM_QUESTION_PROMPT, ANSWER_PROMPT, DEFAULT_DOCUMENT_PROMPT = prep_prompts(reform_template, answer_template)\n",
    "    final_chain = prep_chain(REFORM_QUESTION_PROMPT, llm, retriever, DEFAULT_DOCUMENT_PROMPT, ANSWER_PROMPT, loaded_memory)\n",
    "    final = []\n",
    "\n",
    "    for q in q_lst:\n",
    "        output = stream_chain(final_chain=final_chain, memory=memory, memoryless=memoryless, inputs={\"question\": q}) # Get answer\n",
    "        final.append([f\"Question: {q}\", output[\"answer\"]])\n",
    "        \n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to reformulate the question using the chat history\n",
    "reform_template = \"\"\"Given the following chat history and a follow up question,\n",
    "rephrase the follow up question to be a standalone straightforward question, in its original language.\n",
    "Do not answer the question! Just rephrase reusing informations from the chat history.\n",
    "Make it short and straight to the point.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\n",
    "\"\"\"\n",
    "\n",
    "# Prompt to ask to answer the reformulated question\n",
    "answer_template = \"\"\"Briefly answer the question based only on the following context,\n",
    "do not use any information outside this context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# List of prompts for multi-hop reasoning\n",
    "q_lst = [\"Can you define me what a {concept} is?\", \"What are similar to this concept?\", \"What are their objects' URIs with their labels?\"]\n",
    "\n",
    "# Subject to be enquired about\n",
    "subject = \"urethritis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d252e482a6449e931896a5f6f521c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever = prep_retreiver()\n",
    "llm = prep_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = multi_hop(subject=subject, q_lst=q_lst, retriever=retriever, llm=llm, reform_template=reform_template, answer_template=answer_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question: Can you define me what a urethritis is?'\n",
      " '\\nUrethritis is a type of urethral disease that involves inflammation or infection of the urethra, which is the tube that carries urine from the bladder out of the body. It can be caused by various factors, including bacteria, viruses, and sexually transmitted infections. Symptoms may include pain or burning during urination, frequent urination, and discharge from the urethra.']\n",
      "['Question: What are similar to this concept?'\n",
      " '\\nPossible answer: Urethral disease, urethral syndrome, urethral obstruction, Chlamydia trachomatis urethritis, urethral stricture, infective urethral stricture, urethral gland abscess, urogenital abnormality, urinary tract obstruction, urethral calculus, gonococcal urethritis, urethral benign neoplasm, autoimmune disease of urogenital tract, urinary tract infection, urethral false passage, urinary schistosomiasis, pyelonephritis, Trichomonas urethritis, chlamydia, Chlamydia pneumonia, urethral diverticulum, urethral intrinsic sphincter deficiency, Ureaplasma urealyticum urethritis, urolithiasis, urogenital tuberculosis, bacteriuria, nephritis, parametritis, Mycoplasma genitalium urethritis, prolapse of urethra, bladder disease, urethra cancer, acute pyelonephritis, chronic pyelonephritis, acute pyelonephritis without lesion of renal medullary necrosis, metastasis to the urethra, pyelitis, urethra squamous cell carcinoma,']\n",
      "[\"Question: What are their objects' URIs with their labels?\"\n",
      " \"\\nAnswer: The objects' URIs and labels for similar concepts to urethritis are:\\n\\n1. URI: http://purl.obolibrary.org/obo/DOID_1384 | Label: obsolete Chlamydia trachomatis urethritis\\n2. URI: http://purl.obolibrary.org/obo/DOID_732 | Label: urethral disease\\n3. URI: http://purl.obolibrary.org/obo/DOID_3100 | Label: obsolete Ureaplasma urealyticum urethritis\\n4. URI: http://purl.obolibrary.org/obo/DOID_9589 | Label: urethral calculus\\n5. URI: http://purl.obolibrary.org/obo/DOID_13498 | Label: urethral syndrome\\n6. URI: http://purl.obolibrary.org/obo/DOID_2038 | Label: obsolete urogenital abnormality\\n7. URI: http://purl.obolibrary.org/obo/DOID_1412 | Label: bacteriuria\\n8. URI: http://purl.obolibrary.org/obo/DOID_13558 | Label: obsolete gonococ\"]\n"
     ]
    }
   ],
   "source": [
    "for i in final:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
